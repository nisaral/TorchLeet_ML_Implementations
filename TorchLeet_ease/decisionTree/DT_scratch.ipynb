{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f04e4e09",
   "metadata": {},
   "source": [
    "Problem 1: Decision Tree for Classification (with Gini Index)\n",
    "Problem Statement\n",
    "You are tasked with implementing a decision tree classifier from scratch using NumPy, using the Gini index as the splitting criterion. The decision tree will classify synthetic 2D data points into two classes based on feature thresholds. The implementation will include tree construction, prediction, and evaluation using accuracy.\n",
    "Mathematical Definition:\n",
    "\n",
    "Gini Index for a node:\n",
    "$$\\text{Gini} = 1 - \\sum_{i=1}^c p_i^2$$\n",
    "where $ p_i $ is the proportion of class $ i $ in the node, and $ c $ is the number of classes.\n",
    "Split Criterion: Choose the feature and threshold that minimize the weighted Gini index of child nodes:\n",
    "$$\\text{Gini}_{\\text{split}} = \\frac{n_{\\text{left}}}{n} \\text{Gini}_{\\text{left}} + \\frac{n_{\\text{right}}}{n} \\text{Gini}_{\\text{right}}$$\n",
    "\n",
    "Prediction: Assign the majority class of the leaf node.\n",
    "\n",
    "Requirements\n",
    "\n",
    "Implement a DecisionTreeClassifier class with methods for:\n",
    "\n",
    "fit: Build the tree using recursive splitting.\n",
    "predict: Classify new data points.\n",
    "\n",
    "\n",
    "Use the Gini index to select splits.\n",
    "Handle binary classification with 2D synthetic data.\n",
    "Evaluate accuracy on a test set.\n",
    "\n",
    "Constraints\n",
    "\n",
    "Use only NumPy for data manipulation and tree logic.\n",
    "No scikit-learn or other ML libraries.\n",
    "Max tree depth of 3 to prevent overfitting.\n",
    "Handle batch inputs for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f01c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "np.random.seed(42)\n",
    "\n",
    "X=np.random.rand(100,2)*10\n",
    "# Purpose: Create 100 data points with 2 features, values between 0 and 10.\n",
    "# Theory: np.random.rand generates uniform random numbers in [0, 1). Scaling by 10 gives features in [0, 10). Shape [100, 2] represents 100 samples with 2 features.\n",
    "y=(X[:,0]+X[:,1]>10).astype(int)\n",
    "# Purpose: Create binary labels based on a condition. If the sum of features is greater than 10, label is 1, else 0.\n",
    "# Theory: X[:,0] and X[:,1] access the first and second feature columns. The condition checks if their sum exceeds 10, converting the boolean result to integers (0 or 1).\n",
    "\n",
    "#define the Decision Tree classifier \n",
    "class DecisionTreeClassifier:"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
